{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainX.pickle', 'rb') as f:\n",
    "    trainX = pickle.load(f)\n",
    "    \n",
    "with open('trainY.pickle', 'rb') as f:\n",
    "    trainY = pickle.load(f)\n",
    "    \n",
    "with open('testX.pickle', 'rb') as f:\n",
    "    testX = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining model specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs =10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train,y_test= train_test_split(trainX,trainY,random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling data and handling categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (45000, 28, 28)\n",
      "45000 train samples\n",
      "15000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 300\n",
    "x_test /= 300\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping data so that model can fit on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 784)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (45000, 784))\n",
    "x_test = np.reshape(x_test, (15000, 784))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                3010      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 545,810\n",
      "Trainable params: 545,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(500, input_dim=784), )\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.4))\n",
    "model.add(Dense(300))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.4))\n",
    "\n",
    "# model.add(Dropout(0.4))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/10\n",
      "45000/45000 [==============================] - 7s 148us/step - loss: 0.6057 - acc: 0.7810 - val_loss: 0.5648 - val_acc: 0.7782\n",
      "Epoch 2/10\n",
      "45000/45000 [==============================] - 6s 136us/step - loss: 0.4098 - acc: 0.8502 - val_loss: 0.4001 - val_acc: 0.8483\n",
      "Epoch 3/10\n",
      "45000/45000 [==============================] - 6s 140us/step - loss: 0.3627 - acc: 0.8660 - val_loss: 0.3763 - val_acc: 0.8632\n",
      "Epoch 4/10\n",
      "45000/45000 [==============================] - 6s 137us/step - loss: 0.3302 - acc: 0.8774 - val_loss: 0.3742 - val_acc: 0.8569\n",
      "Epoch 5/10\n",
      "45000/45000 [==============================] - 6s 136us/step - loss: 0.3075 - acc: 0.8843 - val_loss: 0.3414 - val_acc: 0.8760\n",
      "Epoch 6/10\n",
      "45000/45000 [==============================] - 6s 135us/step - loss: 0.2911 - acc: 0.8898 - val_loss: 0.3848 - val_acc: 0.8556\n",
      "Epoch 7/10\n",
      "45000/45000 [==============================] - 6s 140us/step - loss: 0.2760 - acc: 0.8960 - val_loss: 0.3260 - val_acc: 0.8838\n",
      "Epoch 8/10\n",
      "45000/45000 [==============================] - 6s 134us/step - loss: 0.2595 - acc: 0.9013 - val_loss: 0.3206 - val_acc: 0.8860\n",
      "Epoch 9/10\n",
      "45000/45000 [==============================] - 6s 136us/step - loss: 0.2500 - acc: 0.9058 - val_loss: 0.3239 - val_acc: 0.8833\n",
      "Epoch 10/10\n",
      "45000/45000 [==============================] - 7s 148us/step - loss: 0.2408 - acc: 0.9082 - val_loss: 0.3087 - val_acc: 0.8867\n",
      "Test loss: 0.30866910249789553\n",
      "Test accuracy: 0.8866666666348775\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy of this simple sequential model is 88.6\n",
    "#Now we will design more advanced and efficient model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0624 01:39:18.184894  3188 deprecation_wrapper.py:119] From c:\\programdata\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0624 01:39:18.329317  3188 deprecation_wrapper.py:119] From c:\\programdata\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "im_shape = (28,28,1)\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "input_shape=im_shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_shape = (28,28,1)\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/10\n",
      "45000/45000 [==============================] - 403s 9ms/step - loss: 0.5060 - acc: 0.8276 - val_loss: 0.3202 - val_acc: 0.8837\n",
      "Epoch 2/10\n",
      "45000/45000 [==============================] - 407s 9ms/step - loss: 0.3186 - acc: 0.8862 - val_loss: 0.3052 - val_acc: 0.8853\n",
      "Epoch 3/10\n",
      "45000/45000 [==============================] - 391s 9ms/step - loss: 0.2721 - acc: 0.9017 - val_loss: 0.2764 - val_acc: 0.8959\n",
      "Epoch 4/10\n",
      "45000/45000 [==============================] - 482s 11ms/step - loss: 0.2480 - acc: 0.9088 - val_loss: 0.2277 - val_acc: 0.9167\n",
      "Epoch 5/10\n",
      "45000/45000 [==============================] - 518s 12ms/step - loss: 0.2259 - acc: 0.9165 - val_loss: 0.2309 - val_acc: 0.9149\n",
      "Epoch 6/10\n",
      "45000/45000 [==============================] - 502s 11ms/step - loss: 0.2126 - acc: 0.9218 - val_loss: 0.2131 - val_acc: 0.9234\n",
      "Epoch 7/10\n",
      "45000/45000 [==============================] - 521s 12ms/step - loss: 0.2007 - acc: 0.9258 - val_loss: 0.2518 - val_acc: 0.9108\n",
      "Epoch 8/10\n",
      "45000/45000 [==============================] - 738s 16ms/step - loss: 0.1890 - acc: 0.9293 - val_loss: 0.2041 - val_acc: 0.9275\n",
      "Epoch 9/10\n",
      "45000/45000 [==============================] - 814s 18ms/step - loss: 0.1768 - acc: 0.9346 - val_loss: 0.2336 - val_acc: 0.9189\n",
      "Epoch 10/10\n",
      "45000/45000 [==============================] - 968s 22ms/step - loss: 0.1730 - acc: 0.9348 - val_loss: 0.2236 - val_acc: 0.9211\n",
      "Test loss: 0.2235778464714686\n",
      "Test accuracy: 0.9210666666984558\n"
     ]
    }
   ],
   "source": [
    "#H = model.fit(trainX, trainY, validation_data=(test_X, test_Y), batch_size=128, epochs=10)\n",
    "# test_X.shape\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1449\n",
      "           1       0.00      0.00      0.00      1544\n",
      "           2       0.00      0.00      0.00      1529\n",
      "           3       0.06      0.16      0.09      1492\n",
      "           4       0.00      0.00      0.00      1464\n",
      "           5       0.00      0.00      0.00      1504\n",
      "           6       0.08      0.59      0.14      1480\n",
      "           7       0.00      0.00      0.00      1530\n",
      "           8       0.00      0.00      0.00      1482\n",
      "           9       0.00      0.00      0.00      1526\n",
      "\n",
      "    accuracy                           0.07     15000\n",
      "   macro avg       0.01      0.08      0.02     15000\n",
      "weighted avg       0.01      0.07      0.02     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    " \n",
    "print(\"[INFO] evaluating network...\")\n",
    "print(classification_report(y_test.argmax(axis=1), preds.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"testY.pickle\", 'wb') as f:\n",
    "  pickle.dump(Prediction, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
